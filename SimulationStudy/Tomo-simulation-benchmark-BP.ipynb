{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be800a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import ruptures as rpt\n",
    "import csv\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "def function_bai_perron(Y, X, max_cp, min_seg_size):\n",
    "    # Input:\n",
    "    # Y: a vector for the objective variable\n",
    "    # X: (# of samples * # of predictors) matrix for predictors. if you consider a regression model with constant, you should include it in X matrix.\n",
    "    # max_cp: the maximal number of change points that this function will seach\n",
    "    # min_seg_size: the minimal number of obsevations in each segment.\n",
    "    \n",
    "    # output:\n",
    "    # optimal_number: the optimal number of change points. It minimise the BIC\n",
    "    # optimal_location: the optimal lcoations for the optimal number of change points\n",
    "    # RESULT: the obtained solution for the location of change points for each number of change points\n",
    "    # RSS: the computed residual sum of squared for each number of change points\n",
    "    # BIC: the computed value of BIC for each number of change points\n",
    "    # range_of_change_points: the range of change points that this function has searched.\n",
    "    \n",
    "    # matrix [Y, X]\n",
    "    matrix = np.c_[Y, X]\n",
    "    \n",
    "    # list for results\n",
    "    #RSS = []\n",
    "    BIC = []\n",
    "    LOCATION = []\n",
    "    \n",
    "    # Given the number of change points, the locations of change points are estimated.\n",
    "    for i in range(max_cp + 1):\n",
    "        # fitting \n",
    "        algo = rpt.Dynp(model=\"linear\", min_size = min_seg_size, jump = 1).fit(matrix)\n",
    "        \n",
    "        # locations of change points given the number of change points:\n",
    "        result = algo.predict(i)\n",
    "        \n",
    "        # Residuals Sum of Squared\n",
    "        cost = rpt.costs.CostLinear().fit(matrix)\n",
    "        rss = cost.sum_of_costs(result)\n",
    "        \n",
    "        # compute BIC\n",
    "        n_obs = len(Y)\n",
    "        \n",
    "        # calculate degree of freedom to compute BIC\n",
    "        n_coeff = X.shape[1] # the number of coefficients\n",
    "        n_seg = len(result) # the number of segments that is equivalent to 1 + the number of change points\n",
    "        degree_of_freedom = n_coeff*n_seg + 1 + n_seg -1# n_coeff*n_seg + 1 is degree of freedom for the regression model, n_seg -1 is the number of change points that can be also degree of freedom\n",
    "        \n",
    "        # calculate the log-likelihood\n",
    "        # When we have change points, we formulate the regression model by indicator function.\n",
    "        # Hence we can estimate single regression model even though we have multiple change points\n",
    "        if n_seg == 1:\n",
    "            log_likelihood = sm.OLS(matrix[0:result[0], 0], matrix[0:result[0], 1:]).fit().llf\n",
    "        else:\n",
    "            matrix_for_hadamard_product = np.zeros((n_obs, n_coeff))\n",
    "            matrix_for_hadamard_product[0:result[0],:] = 1\n",
    "            matrix_X = np.multiply(X, matrix_for_hadamard_product)\n",
    "            for j in range(n_seg-1):\n",
    "                matrix_for_hadamard_product = np.zeros((n_obs, n_coeff))\n",
    "                matrix_for_hadamard_product[result[j]:result[j+1],:] = 1\n",
    "                temp = np.multiply(X, matrix_for_hadamard_product)\n",
    "                matrix_X = np.c_[matrix_X, temp]\n",
    "            \n",
    "            log_likelihood = sm.OLS(matrix[:, 0], matrix_X).fit().llf\n",
    "        \n",
    "        # BIC = degree of freedom*log(# of samples) - 2 * log lilkelihood\n",
    "        bic = degree_of_freedom*np.log(n_obs)- 2*(log_likelihood)\n",
    "\n",
    "        # save the result\n",
    "        LOCATION.append(result)\n",
    "        #RSS.append(rss)\n",
    "        BIC.append(bic)\n",
    "    \n",
    "    # best change point\n",
    "    optimal_number = BIC.index(min(BIC))\n",
    "    optimal_location = LOCATION[optimal_number]\n",
    "    #range_of_change_points = list(range(max_cp + 1))\n",
    "\n",
    "    return(optimal_number, optimal_location)\n",
    "\n",
    "\n",
    "\n",
    "def generate_five_variate(n,SNR,rho):\n",
    "    beta1 = np.array([1,1,1,0,1])\n",
    "    beta2 = np.array([-1,-1,-1,0,-1])\n",
    "    p = len(beta1)\n",
    "    Sigma = np.zeros((p,p));\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            Sigma[i,j] = rho**(abs(i-j))\n",
    "    X = np.random.multivariate_normal(mean =np.zeros(p), cov = Sigma, size = n)\n",
    "    noise1 = np.random.normal(0,np.sqrt(np.var(X[:int(n/2)]@beta1)/SNR), size = int(n/2)) \n",
    "    noise2 = np.random.normal(0,np.sqrt(np.var(X[:int(n/2)]@beta2)/SNR), size = int(n/2)) \n",
    "    Y1 = X[:int(n/2)]@beta1 + noise1\n",
    "    Y2 = X[int(n/2):]@beta2 + noise2\n",
    "    Y = np.r_[Y1,Y2]\n",
    "    \n",
    "    return(Y, X)\n",
    "\n",
    "\n",
    "\n",
    "SNR_list = np.array([6, 3.52, 2.07, 1.22, 0.71])\n",
    "rho_list = np.array([0, 0.3, 0.7])\n",
    "n_list = np.array([1000])\n",
    "\n",
    "header = ['Repitition','Time','rho', 'SNR', 'n', 'The number of CP', 'Location of CP']#, 'beta_hat', 'nonzero count']\n",
    "f = open('simulation_five_variate_benchmark_BP.csv', 'w')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(header)\n",
    "f.close()\n",
    "\n",
    "def to_repeat(rep):\n",
    "    for n in n_list:\n",
    "        for SNR in SNR_list:\n",
    "            for rho in rho_list:\n",
    "                tik = time.time()\n",
    "                Y, X = generate_five_variate(n,SNR,rho)\n",
    "                opt_num, opt_location= function_bai_perron(Y, X, 5, 3) # max_cp = 5, min_seg = 3\n",
    "                tok = time.time()\n",
    "                duration = tok - tik\n",
    "                # Write result\n",
    "                resultrow = [rep,duration,rho,SNR, n, opt_num, opt_location]\n",
    "                f = open('simulation_five_variate_benchmark_BP.csv', 'a')\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(resultrow)\n",
    "                f.close()\n",
    "                \n",
    "Parallel(n_jobs = 8)(delayed(to_repeat)(rep) for rep in range(500)) #Tomo's machine has 8 cores.\n",
    "\n",
    "\n",
    "# Answer:\n",
    "# the number of CP = 1\n",
    "# Location of CP = [500, 1000]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a980cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61f3dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
